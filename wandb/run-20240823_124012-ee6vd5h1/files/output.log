Train transforms: [<utils.data_utils.PointcloudToTensor object at 0x0000029AE1A16270>, <utils.data_utils.RandomSample object at 0x0000029A8B823FE0>, <utils.data_utils.AugmScale object at 0x0000029A8A18F4A0>, <utils.data_utils.AugmRotate object at 0x0000029A8BA53980>, <utils.data_utils.AugmRotatePerturbation object at 0x0000029A8B932060>, <utils.data_utils.AugmTranslate object at 0x0000029A8B9329F0>, <utils.data_utils.AugmJitter object at 0x0000029A8B930B60>]
ModelNet40_OOD - Reading data from h5py file: ./3D_OS_release_data\modelnet40_normal_resampled\ood_sets_cache\SR1_train.h5
ModelNet40_OOD - split: train, categories: {'chair': 0, 'bookshelf': 1, 'door': 2, 'sink': 3, 'sofa': 4}
SR1 train_data len: 2378
ModelNet40_OOD - Reading data from h5py file: ./3D_OS_release_data\modelnet40_normal_resampled\ood_sets_cache\SR1_test.h5
ModelNet40_OOD - split: test, categories: {'chair': 0, 'bookshelf': 1, 'door': 2, 'sink': 3, 'sofa': 4}
SR1 train synset: {'chair': 0, 'bookshelf': 1, 'door': 2, 'sink': 3, 'sofa': 4}
Source: SR1
Num training classes: 5
Clf - feature encoder: pn2-msg
Clf Head - num classes: 5, input dim: 1024, act: relu, dropout: 0.5
Model:
Classifier(
  (enco): Pointnet2_MSG_Y(
    (sa1): PointNetSetAbstractionMsg(
      (conv_blocks): ModuleList(
        (0): ModuleList(
          (0): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ModuleList(
          (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): ModuleList(
          (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (bn_blocks): ModuleList(
        (0): ModuleList(
          (0-1): 2 x BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): ModuleList(
          (0-1): 2 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): ModuleList(
          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (sa2): PointNetSetAbstractionMsg(
      (conv_blocks): ModuleList(
        (0): ModuleList(
          (0): Conv2d(323, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (1-2): 2 x ModuleList(
          (0): Conv2d(323, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (bn_blocks): ModuleList(
        (0): ModuleList(
          (0-1): 2 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1-2): 2 x ModuleList(
          (0-1): 2 x BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (sa3): PointNetSetAbstraction(
      (mlp_convs): ModuleList(
        (0): Conv2d(643, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
      )
      (mlp_bns): ModuleList(
        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (penultimate): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=False)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=512, out_features=256, bias=False)
  )
  (head): Sequential(
    (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=256, out_features=5, bias=True)
  )
)
param count:
1.7376 M
Loss: CE
C:\Users\matti\Desktop\AML\Codice\nostro\SemNov_AML_DAAI_23-24-main\classifiers\trainer_cla_md.py:320: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=opt.use_amp)
Traceback (most recent call last):
  File "C:\Users\matti\Desktop\AML\Codice\nostro\SemNov_AML_DAAI_23-24-main\classifiers\trainer_cla_md.py", line 715, in <module>
    main()
  File "C:\Users\matti\Desktop\AML\Codice\nostro\SemNov_AML_DAAI_23-24-main\classifiers\trainer_cla_md.py", line 706, in main
    train(args, config)
  File "C:\Users\matti\Desktop\AML\Codice\nostro\SemNov_AML_DAAI_23-24-main\classifiers\trainer_cla_md.py", line 397, in train
    train_epoch_cla(
  File "C:\Users\matti\Desktop\AML\Codice\nostro\SemNov_AML_DAAI_23-24-main\classifiers\common.py", line 25, in train_epoch_cla
    for i, batch in enumerate(train_loader, 0):
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\matti\Desktop\virtual_enviroments\aml\Lib\site-packages\torch\utils\data\dataloader.py", line 440, in __iter__
    return self._get_iterator()
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\matti\Desktop\virtual_enviroments\aml\Lib\site-packages\torch\utils\data\dataloader.py", line 388, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\matti\Desktop\virtual_enviroments\aml\Lib\site-packages\torch\utils\data\dataloader.py", line 1038, in __init__
    w.start()
  File "C:\Users\matti\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\matti\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\matti\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\matti\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 95, in __init__
    reduction.dump(process_obj, to_child)
  File "C:\Users\matti\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
OSError: [Errno 22] Invalid argument